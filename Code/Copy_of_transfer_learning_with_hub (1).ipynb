{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mouting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCpTGLxbb-pq",
        "outputId": "9db1d987-0456-45aa-e2f1-8e4dfd7ae9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.callbacks import *\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "7gDrkcZfcBwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize = 32\n",
        "imageHeight = 224\n",
        "imageWidth = 224\n",
        "randomisingSeed = 108\n",
        "colorMode = \"rgb\"\n",
        "validationSplitFraction = 0.2\n",
        "imageInterpolationMethod  = \"bilinear\"\n",
        "cropToPreserveAspectRatioWhileResizing = False\n",
        "\n",
        "augmentDataset = True\n",
        "cropBottomPanel = False\n",
        "\n",
        "earlyStoppingMetric = \"val_accuracy\"\n",
        "earlyStoppingMinimumImprovementCriterion = 0.005\n",
        "earlyStoppingPatience = 30\n",
        "\n",
        "baselineAccuracy = 0.5\n",
        "\n",
        "learningRateReductionMetric = 'val_loss'\n",
        "patienceForLearningRateReduction = 10\n",
        "learningRateReductionFactor = 0.1\n",
        "learningRateReductionMinimumImprovementCriterion = 0.0001\n",
        "learningRateReductionCooldown = 25\n",
        "minimumLearningRate = 0\n",
        "\n",
        "useTensorboard = False\n",
        "\n",
        "useArchitecture = ['customCNN', 'ResNetTransfer'][1]\n",
        "doSeperateFineTuning = True\n",
        "makeTransferModelTrainable = False\n",
        "addConvolutionLayersOnBaseModel = True\n",
        "\n",
        "maxPoolingSize = (2, 2)\n",
        "maxPollingPadding = 'valid'\n",
        "\n",
        "convolutionKernelSize = 3\n",
        "convolutionKernelRegulariser = None\n",
        "convolutionActivityRegulariser = None"
      ],
      "metadata": {
        "id": "sCFAz3dZe3ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrIUV3V0xDL_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "b11bc19f-eca2-41ea-8b8f-385ca9b9f866"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d3abfdcb1059>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    rootLogsDirectory = '/content/drive/MyDrive/SEMProject/' + datasetName + \"/logs/'\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ],
      "source": [
        "# Daatset locations on G drive\n",
        "# Make sure that the daatset folder is there in drive\n",
        "# And that a seeprate tmpModelBackup folder has been created for each model that runs at a given time\n",
        "datasetName = 'SEM100'\n",
        "modelName = 'simpleTransferLearning_InceptionV3_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefault'\n",
        "trainingDataPath = '/content/drive/MyDrive/SEMProject/' + datasetName + '/train'\n",
        "testingDataPath = '/content/drive/MyDrive/SEMProject/' + datasetName + '/test'\n",
        "historySaveLocation = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/history/' + modelName + 'data.pickle'\n",
        "fineTuneHistorySaveLocation = '/content/drive/My Drive/' + datasetName + '/models/history/' + modelName + '_fineTune_data.pickle'\n",
        "modelSaveLocation = '/content/drive/MyDrive/SEMProject/SEM100/models/finalModels/' + modelName + '.h5'\n",
        "fineTuneModelSaveLocation = '/content/drive/MyDrive/SEMProject/SEM100/models/finalModels/' + modelName + '_fineTune.h5'\n",
        "\n",
        "rootLogsDirectory = '/content/drive/MyDrive/SEMProject/' + datasetName + \"/logs/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getDataset(batchSize, imageHeight, imageWidth, randomisingSeed, colorMode, validationSplitFraction, imageInterpolationMethod, cropToPreserveAspectRatioWhileResizing, augmentDataset, cropBottomPanel):\n",
        "  trainingDataset, validationDataset = tf.keras.utils.image_dataset_from_directory(\n",
        "      directory = trainingDataPath,\n",
        "      labels = \"inferred\",\n",
        "      label_mode = \"categorical\",\n",
        "      color_mode = colorMode,\n",
        "      batch_size = batchSize,\n",
        "      image_size = (imageHeight, imageWidth),\n",
        "      seed = randomisingSeed,\n",
        "      shuffle = True,\n",
        "      validation_split = validationSplitFraction,\n",
        "      subset=\"both\",\n",
        "      interpolation = imageInterpolationMethod,\n",
        "      crop_to_aspect_ratio = cropToPreserveAspectRatioWhileResizing\n",
        "      )\n",
        "\n",
        "  testingDataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory = testingDataPath,\n",
        "    labels = 'inferred',\n",
        "    label_mode = \"categorical\",\n",
        "    color_mode = colorMode,\n",
        "    batch_size = batchSize,\n",
        "    image_size = (imageHeight, imageWidth),\n",
        "    seed=  randomisingSeed,\n",
        "    shuffle = True,\n",
        "    interpolation = imageInterpolationMethod,\n",
        "    crop_to_aspect_ratio = cropToPreserveAspectRatioWhileResizing\n",
        "    )\n",
        "\n",
        "  classNames = np.array(trainingDataset.class_names)\n",
        "  print(classNames)\n",
        "\n",
        "  def cropBottomPanel(image, label):\n",
        "    return tf.image.crop_and_resize(image = image , boxes = np.array( [[0, 0, 600/768, 1]] ) ,box_indices = [0], crop_size = (imageHeight, imageWidth), method = imageInterpolationMethod,extrapolation_value = 0.0,name = None), label\n",
        "\n",
        "  #if cropBottomPanel:\n",
        "    #trainingDataset = trainingDataset.map(cropBottomPanel)\n",
        "    #validationDataset = validationDataset.map(cropBottomPanel)\n",
        "    #testingDataset = testingDataset.map(cropBottomPanel)\n",
        "    #imageHeight = int(imageHeight * 600/ 768)\n",
        "\n",
        "  augmentedTrainingDataset = trainingDataset\n",
        "\n",
        "  if augmentDataset:\n",
        "    dataAugmentation = keras.Sequential(\n",
        "        [\n",
        "            layers.RandomRotation(factor = (-0.5, 0.5), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomFlip(mode = \"horizontal_and_vertical\", seed = randomisingSeed),\n",
        "            layers.RandomTranslation(height_factor = (-0.2, 0.2), width_factor = (-0.2, 0.2), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomZoom(height_factor = (-0.3, 0.3), width_factor = (-0.2, 0.2), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomContrast(factor = (0.4, 0.3), seed = randomisingSeed)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    augmentedTrainingDataset = trainingDataset.map(lambda x, y: (dataAugmentation(x), y))\n",
        "\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "  if augmentDataset:\n",
        "    augmentedTrainingDataset = augmentedTrainingDataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "  else:\n",
        "    trainingDataset = trainingDataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  validationDataset = validationDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return trainingDataset, augmentedTrainingDataset, validationDataset, testingDataset, classNames, imageHeight"
      ],
      "metadata": {
        "id": "iaMjs4IIfT85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingDataset, augmentedTrainingDataset, validationDataset, testingDataset, classNames, imageHeight = getDataset(batchSize = batchSize,\n",
        "                                                                                                      imageHeight = imageHeight, imageWidth = imageWidth,\n",
        "                                                                                                      randomisingSeed = randomisingSeed,\n",
        "                                                                                                      colorMode = colorMode,\n",
        "                                                                                                      validationSplitFraction = validationSplitFraction,\n",
        "                                                                                                      imageInterpolationMethod = imageInterpolationMethod,\n",
        "                                                                                                      cropToPreserveAspectRatioWhileResizing = cropToPreserveAspectRatioWhileResizing,\n",
        "                                                                                                      augmentDataset = augmentDataset, cropBottomPanel = cropBottomPanel)"
      ],
      "metadata": {
        "id": "tRtp6722fcjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NzDDWEMCL20"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "trainingDataset = trainingDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "validationDataset = validationDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmJMKFw7C4ki"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "trainingDataset = trainingDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validationDataset = validationDataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0JyiEZ0imgf"
      },
      "outputs": [],
      "source": [
        "for imagesBatch, labelsBatch in trainingDataset:\n",
        "  print(imagesBatch.shape)\n",
        "  print(labelsBatch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gTN7M_GxDLx"
      },
      "source": [
        "### Run the classifier on a batch of images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3fvrZR8xDLv"
      },
      "source": [
        "Now, run the classifier on an image batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcFeNcrehEue"
      },
      "outputs": [],
      "source": [
        "resultsBatch = classifier.predict(trainingDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wK2ky45hlyS"
      },
      "outputs": [],
      "source": [
        "predicted_classNames = imagenet_labels[tf.math.argmax(resultsBatch, axis=-1)]\n",
        "predicted_classNames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmvSWg9nxDLa"
      },
      "source": [
        "Check how these predictions line up with the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXTB22SpxDLP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(imagesBatch[n])\n",
        "  plt.title(predicted_classNames[n])\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"ImageNet predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "### Download the headless model\n",
        "\n",
        "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning.\n",
        "\n",
        "Select a <a href=\"https://arxiv.org/abs/1801.04381\" class=\"external\">MobileNetV2</a> pre-trained model <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" class=\"external\">from TensorFlow Hub</a>. Any <a href=\"https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\" class=\"external\">compatible image feature vector model</a> from TensorFlow Hub will work here, including the examples from the drop-down menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bw8Jf94DSnP"
      },
      "outputs": [],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "\n",
        "featureExtractorModel = inception_v3 #@param [\"mobilenet_v2\", \"inception_v3\"] {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHugQF-PD"
      },
      "source": [
        "Create the feature extractor by wrapping the pre-trained model as a Keras layer with [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer). Use the `trainable=False` argument to freeze the variables, so that the training only modifies the new classifier layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wB030nezBwI"
      },
      "outputs": [],
      "source": [
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    featureExtractorModel,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QzVdu4ZhcDE"
      },
      "source": [
        "The feature extractor returns a 1280-long vector for each image (the image batch size remains at 32 in this example):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of7i-35F09ls"
      },
      "outputs": [],
      "source": [
        "feature_batch = feature_extractor_layer(imagesBatch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Attach a classification head\n",
        "\n",
        "To complete the model, wrap the feature extractor layer in a `tf.keras.Sequential` model and add a fully-connected layer for classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQq_kCWzlqSu"
      },
      "outputs": [],
      "source": [
        "numberOfClasses = len(classNames)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(numberOfClasses)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyhX4VCFmzVS"
      },
      "outputs": [],
      "source": [
        "predictions = model(imagesBatch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQdUaTkzm3jQ"
      },
      "outputs": [],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xRx8Rjzm67O"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])\n",
        "\n",
        "log_dir = rootLogsDirectory + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getCallbacks(datasetName, modelName, earlyStoppingMetric, earlyStoppingMinimumImprovementCriterion, earlyStoppingPatience,\n",
        "                 baselineAccuracy,\n",
        "                 learningRateReductionMetric, learningRateReductionFactor, patienceForLearningRateReduction,\n",
        "                 learningRateReductionMinimumImprovementCriterion, learningRateReductionCooldown):\n",
        "  callbackList = []\n",
        "\n",
        "  callbackList.append(BackupAndRestore(backup_dir = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/tmpModelBackup/' + modelName + 'epoch_{epoch:04d}.h5', save_freq = 'epoch',\n",
        "                                    delete_checkpoint = True, save_before_preemption = False))\n",
        "\n",
        "  callbackList.append(EarlyStopping(monitor = earlyStoppingMetric, min_delta = earlyStoppingMinimumImprovementCriterion, patience = earlyStoppingPatience,\n",
        "                                    verbose = 1, mode = 'auto', baseline = None, restore_best_weights = True, start_from_epoch = 0))\n",
        "\n",
        "  #def learningrateSchedule(currentEpochNumber, learningRatefromPreviousEpoch):\n",
        "  #  learningRateForCurrentEpoch = learningRatefromPreviousEpoch\n",
        "  #  return learningRateForCurrentEpoch\n",
        "\n",
        "  #callbackList.append(LearningRateScheduler(learningRateSchedule(epoch, lr), verbose = 1))\n",
        "\n",
        "  #callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/allTrainingModels/' + modelName + 'epoch_{epoch:04d}.h5',\n",
        "  #                                    monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "  #                                    options = None, initial_value_threshold = None))\n",
        "  callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject' + datasetName + '/models/finalModels/' + modelName + 'MostAccurateEpoch_{epoch:04d}.h5',\n",
        "                                      monitor = 'val_accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "                                      options = None, initial_value_threshold = baselineAccuracy))\n",
        "  callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject' + datasetName + '/models/finalModels/' + modelName + 'LeastLossEpoch_{epoch:04d}.h5',\n",
        "                                      monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "                                      options = None, initial_value_threshold = None))\n",
        "\n",
        "  callbackList.append(ReduceLROnPlateau(monitor = learningRateReductionMetric, factor = learningRateReductionFactor, patience = patienceForLearningRateReduction,\n",
        "                                        verbose = 1, mode='auto', min_delta = learningRateReductionMinimumImprovementCriterion, cooldown = learningRateReductionCooldown,\n",
        "                                        min_lr = minimumLearningRate))\n",
        "\n",
        "  callbackList.append(TerminateOnNaN())\n",
        "\n",
        "  tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "  return callbackList"
      ],
      "metadata": {
        "id": "V03LhODI5rsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI0yAKd-nARd"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "history = model.fit(trainingDataset,\n",
        "                    validation_data=validationDataset,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=tensorboard_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiDbmiAK_h03"
      },
      "source": [
        "Start the TensorBoard to view how the metrics change with each epoch and to track other scalar values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yVJar0MiT2t"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a9d7cab8c8"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/images/tensorboard_transfer_learning_with_hub.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "### Check the predictions\n",
        "\n",
        "Obtain the ordered list of class names from the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGbEf5l1I4jz"
      },
      "outputs": [],
      "source": [
        "predicted_batch = model.predict(imagesBatch)\n",
        "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = classNames[predicted_id]\n",
        "print(predicted_label_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "Plot the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW3Ic_ZlwtrZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(imagesBatch[n])\n",
        "  plt.title(predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRcJnAABr22x"
      },
      "source": [
        "## Export and reload your model\n",
        "\n",
        "Now that you've trained the model, export it as a SavedModel for reusing it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcqg-RmsLno"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "model.save(export_path)\n",
        "\n",
        "export_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQ9liIUsPsi"
      },
      "source": [
        "Confirm that you can reload the SavedModel and that the model is able to output the same results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nI5fvkAQvbS"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.keras.models.load_model(export_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZO14taYPH6"
      },
      "outputs": [],
      "source": [
        "resultsBatch = model.predict(imagesBatch)\n",
        "reloaded_resultsBatch = reloaded.predict(imagesBatch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtjsIPjQnPyM"
      },
      "outputs": [],
      "source": [
        "abs(reloaded_resultsBatch - resultsBatch).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jor83-LqI8xW"
      },
      "outputs": [],
      "source": [
        "reloaded_predicted_id = tf.math.argmax(reloaded_resultsBatch, axis=-1)\n",
        "reloaded_predicted_label_batch = classNames[reloaded_predicted_id]\n",
        "print(reloaded_predicted_label_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkQIBksVkxPO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(imagesBatch[n])\n",
        "  plt.title(reloaded_predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSBRrW-MqBbk"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can use the SavedModel to load for inference or convert it to a [TensorFlow Lite](https://www.tensorflow.org/lite/models/convert/)  model (for on-device machine learning) or a [TensorFlow.js](https://www.tensorflow.org/js/tutorials#convert_pretrained_models_to_tensorflowjs) model (for machine learning in JavaScript).\n",
        "\n",
        "Discover [more tutorials](https://www.tensorflow.org/hub/tutorials) to learn how to use pre-trained models from TensorFlow Hub on image, text, audio, and video tasks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W_tvPdyfA-BL"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}