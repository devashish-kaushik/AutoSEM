{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR6Orsw-r7ZG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.models import Model,load_model\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "3_R8pYevNd5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "import collections\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from PIL import Image\n",
        "import math"
      ],
      "metadata": {
        "id": "ivamhUnPNfbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mouting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NHtHmvip5pT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link to the provided data\n",
        "trainPath='/content/drive/MyDrive/steelDefects/train'\n",
        "testPath='/content/drive/MyDrive/steelDefects/test'"
      ],
      "metadata": {
        "id": "VKhyM2pn5q9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(9, 10, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Rx_aWJEK571U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testSize=40\n",
        "batchSize=15\n",
        "epochs=200\n",
        "targetSize=(300,300)"
      ],
      "metadata": {
        "id": "vgb_YhNF4wj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,\n",
        "                                   rotation_range=50,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   brightness_range = [0.4, 1.2],\n",
        "                                   fill_mode='nearest',\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, rotation_range=50,)"
      ],
      "metadata": {
        "id": "PI19_Gzj5AKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentedTrain = [train_generator[0][0][j] for j in range(9) for i in range(16)]\n",
        "plotImages(augmentedTrain)"
      ],
      "metadata": {
        "id": "eeupS5el6EtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentedTest = [validation_generator[0][0][j] for j in range(9) for i in range(16)]\n",
        "plotImages(augmentedTest)"
      ],
      "metadata": {
        "id": "R7f2TeiR6GLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "                  trainPath,\n",
        "                  target_size=targetSize,\n",
        "                  batch_size=batchSize,\n",
        "                  class_mode='categorical',\n",
        "                  subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "                       trainPath,\n",
        "                       target_size=targetSize,\n",
        "                       batch_size=batchSize,\n",
        "                       class_mode='categorical',\n",
        "                       subset='validation')"
      ],
      "metadata": {
        "id": "H0CpvCYZ5APs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CVRun(gaussianProcess, NoOfSplits, X, y):\n",
        "  kf = KFold(n_splits=NoOfSplits)\n",
        "\n",
        "  # For tracking results of each split\n",
        "  errors = []\n",
        "  kernels = []\n",
        "\n",
        "  # Iterating over all splits\n",
        "  for idx, (train, val) in enumerate(kf.split(X)):\n",
        "      # Seperate the parts of the data\n",
        "      CV_XTrain = X.values[train]\n",
        "      CV_XVal = X.values[val]\n",
        "      CV_YTrain = y.values[train]\n",
        "      CV_YVal = y.values[val]\n",
        "\n",
        "      # Normalise the dataset\n",
        "      CV_XTrain = scaler.fit_transform(CV_XTrain)\n",
        "      CV_XVal = scaler.transform(CV_XVal)\n",
        "\n",
        "      # Model fit and prediction\n",
        "      model = gaussianProcess.fit(CV_XTrain, CV_YTrain)\n",
        "      Predicted_YTrain = model.predict(CV_XTrain)\n",
        "      Predicted_YVal = model.predict(CV_XVal)\n",
        "\n",
        "\n",
        "      # Computing errors\n",
        "      rmse_val = np.sqrt(mean_squared_error(CV_YVal, Predicted_YVal))\n",
        "\n",
        "      errors.append(rmse_val)\n",
        "      kernels.append(model.kernel_)\n",
        "\n",
        "  # Find and return the mean optimal parameter and error values over all splits\n",
        "  sigma_cs = []\n",
        "  sigma_ls = []\n",
        "\n",
        "  for k in kernels:\n",
        "      sigma_cs.append(k.k1.constant_value)\n",
        "      sigma_ls.append(k.k2.length_scale)\n",
        "  k_best = np.median(sigma_cs) * RBF(length_scale=np.median(sigma_ls), length_scale_bounds=(1e-4, 1e2))\n",
        "\n",
        "  print(errors)\n",
        "  print(pd.DataFrame(errors).mean()[0])\n",
        "\n",
        "  return pd.DataFrame(errors).mean()[0], k_best"
      ],
      "metadata": {
        "id": "rCJFQron5ATK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}