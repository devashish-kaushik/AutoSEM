{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCpTGLxbb-pq",
        "outputId": "983c7f31-a89e-4330-8fba-866648858a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mouting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gDrkcZfcBwQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import gc\n",
        "import pickle\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.callbacks import *\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "from tensorflow.math import confusion_matrix\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCFAz3dZe3ro"
      },
      "outputs": [],
      "source": [
        "batchSize = 32\n",
        "imageHeight = 224\n",
        "imageWidth = 224\n",
        "randomisingSeed = 108\n",
        "colorMode = \"rgb\"\n",
        "validationSplitFraction = 0.2\n",
        "imageInterpolationMethod  = \"bilinear\"\n",
        "cropToPreserveAspectRatioWhileResizing = False\n",
        "\n",
        "augmentDataset = True\n",
        "cropBottomPanel = False\n",
        "\n",
        "earlyStoppingMetric = \"val_accuracy\"\n",
        "earlyStoppingMinimumImprovementCriterion = 0.001\n",
        "earlyStoppingPatience = 7\n",
        "\n",
        "baselineAccuracy = 0.5\n",
        "\n",
        "learningRateReductionMetric = 'val_loss'\n",
        "patienceForLearningRateReduction = 3\n",
        "learningRateReductionFactor = 0.1\n",
        "learningRateReductionMinimumImprovementCriterion = 0.001\n",
        "learningRateReductionCooldown = 3\n",
        "minimumLearningRate = 0\n",
        "\n",
        "useTensorboard = False\n",
        "\n",
        "useArchitecture = ['customCNN', 'transfer'][1]\n",
        "doSeperateFineTuning = False\n",
        "makeTransferModelTrainable = False\n",
        "addConvolutionLayersOnBaseModel = True\n",
        "\n",
        "maxPoolingSize = (2, 2)\n",
        "maxPollingPadding = 'valid'\n",
        "\n",
        "convolutionKernelSize = 3\n",
        "convolutionKernelRegulariser = None\n",
        "convolutionActivityRegulariser = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrIUV3V0xDL_"
      },
      "outputs": [],
      "source": [
        "# Daatset locations on G drive\n",
        "# Make sure that the daatset folder is there in drive\n",
        "# And that a seeprate tmpModelBackup folder has been created for each model that runs at a given time\n",
        "datasetName = 'SEM500'\n",
        "modelName = 'SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefault'\n",
        "trainingDataPath = '/content/drive/MyDrive/SEMProject/' + datasetName + '/train'\n",
        "testingDataPath = '/content/drive/MyDrive/SEMProject/' + datasetName + '/test'\n",
        "historySaveLocation = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/history/' + modelName + 'data.pickle'\n",
        "fineTuneHistorySaveLocation = '/content/drive/My Drive/' + datasetName + '/models/history/' + modelName + '_fineTune_data.pickle'\n",
        "modelSaveLocation = '/content/drive/MyDrive/SEMProject/SEM500/models/finalModels/' + modelName + '.h5'\n",
        "fineTuneModelSaveLocation = '/content/drive/MyDrive/SEMProject/SEM500/models/finalModels/' + modelName + '_fineTune.h5'\n",
        "\n",
        "rootLogsDirectory = '/content/drive/MyDrive/SEMProject/' + datasetName + \"/logs/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaMjs4IIfT85"
      },
      "outputs": [],
      "source": [
        "def getDataset(batchSize, imageHeight, imageWidth, randomisingSeed, colorMode, validationSplitFraction, imageInterpolationMethod, cropToPreserveAspectRatioWhileResizing, augmentDataset, cropBottomPanel):\n",
        "  trainingDataset, validationDataset = tf.keras.utils.image_dataset_from_directory(\n",
        "      directory = trainingDataPath,\n",
        "      labels = \"inferred\",\n",
        "      label_mode = \"categorical\",\n",
        "      color_mode = colorMode,\n",
        "      batch_size = batchSize,\n",
        "      image_size = (imageHeight, imageWidth),\n",
        "      seed = randomisingSeed,\n",
        "      shuffle = True,\n",
        "      validation_split = validationSplitFraction,\n",
        "      subset=\"both\",\n",
        "      interpolation = imageInterpolationMethod,\n",
        "      crop_to_aspect_ratio = cropToPreserveAspectRatioWhileResizing\n",
        "      )\n",
        "\n",
        "  testingDataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory = testingDataPath,\n",
        "    labels = 'inferred',\n",
        "    label_mode = \"categorical\",\n",
        "    color_mode = colorMode,\n",
        "    batch_size = batchSize,\n",
        "    image_size = (imageHeight, imageWidth),\n",
        "    seed=  randomisingSeed,\n",
        "    shuffle = True,\n",
        "    interpolation = imageInterpolationMethod,\n",
        "    crop_to_aspect_ratio = cropToPreserveAspectRatioWhileResizing\n",
        "    )\n",
        "\n",
        "  classNames = np.array(trainingDataset.class_names)\n",
        "  print(classNames)\n",
        "\n",
        "  def cropBottomPanel(image, label):\n",
        "    return tf.image.crop_and_resize(image = image , boxes = np.array( [[0, 0, 600/768, 1]] ) ,box_indices = [0], crop_size = (imageHeight, imageWidth), method = imageInterpolationMethod,extrapolation_value = 0.0,name = None), label\n",
        "\n",
        "  #if cropBottomPanel:\n",
        "    #trainingDataset = trainingDataset.map(cropBottomPanel)\n",
        "    #validationDataset = validationDataset.map(cropBottomPanel)\n",
        "    #testingDataset = testingDataset.map(cropBottomPanel)\n",
        "    #imageHeight = int(imageHeight * 600/ 768)\n",
        "\n",
        "  augmentedTrainingDataset = trainingDataset\n",
        "\n",
        "  if augmentDataset:\n",
        "    dataAugmentation = keras.Sequential(\n",
        "        [\n",
        "            layers.RandomRotation(factor = (-0.5, 0.5), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomFlip(mode = \"horizontal_and_vertical\", seed = randomisingSeed),\n",
        "            layers.RandomTranslation(height_factor = (-0.2, 0.2), width_factor = (-0.2, 0.2), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomZoom(height_factor = (-0.3, 0.3), width_factor = (-0.2, 0.2), fill_mode = \"nearest\", interpolation = imageInterpolationMethod, seed = randomisingSeed),\n",
        "            layers.RandomContrast(factor = (0.4, 0.3), seed = randomisingSeed)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    augmentedTrainingDataset = trainingDataset.map(lambda x, y: (dataAugmentation(x), y))\n",
        "\n",
        "  AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "  if augmentDataset:\n",
        "    augmentedTrainingDataset = augmentedTrainingDataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "  else:\n",
        "    trainingDataset = trainingDataset.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  validationDataset = validationDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return trainingDataset, augmentedTrainingDataset, validationDataset, testingDataset, classNames, imageHeight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRtp6722fcjP",
        "outputId": "21817a80-a346-411d-e505-391fa115c3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4349 files belonging to 10 classes.\n",
            "Using 3480 files for training.\n",
            "Using 869 files for validation.\n",
            "Found 856 files belonging to 10 classes.\n",
            "['Biological' 'Fibres' 'Films_Coated_Surface'\n",
            " 'MEMS_devices_and_electrodes' 'Nanowires' 'Particles' 'Patterned_surface'\n",
            " 'Porous_Sponge' 'Powder' 'Tips']\n"
          ]
        }
      ],
      "source": [
        "trainingDataset, augmentedTrainingDataset, validationDataset, testingDataset, classNames, imageHeight = getDataset(batchSize = batchSize,\n",
        "                                                                                                      imageHeight = imageHeight, imageWidth = imageWidth,\n",
        "                                                                                                      randomisingSeed = randomisingSeed,\n",
        "                                                                                                      colorMode = colorMode,\n",
        "                                                                                                      validationSplitFraction = validationSplitFraction,\n",
        "                                                                                                      imageInterpolationMethod = imageInterpolationMethod,\n",
        "                                                                                                      cropToPreserveAspectRatioWhileResizing = cropToPreserveAspectRatioWhileResizing,\n",
        "                                                                                                      augmentDataset = augmentDataset, cropBottomPanel = cropBottomPanel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NzDDWEMCL20"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "trainingDataset = trainingDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "augmentedTrainingDataset = augmentedTrainingDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "validationDataset = validationDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
        "testingDataset = testingDataset.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmJMKFw7C4ki"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "trainingDataset = trainingDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "augmentedTrainingDataset = augmentedTrainingDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validationDataset = validationDataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "testingDataset = testingDataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0JyiEZ0imgf"
      },
      "outputs": [],
      "source": [
        "for imagesBatch, labelsBatch in trainingDataset:\n",
        "  print(imagesBatch.shape)\n",
        "  print(labelsBatch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "### Download the headless model\n",
        "\n",
        "TensorFlow Hub also distributes models without the top classification layer. These can be used to easily perform transfer learning.\n",
        "\n",
        "Select a <a href=\"https://arxiv.org/abs/1801.04381\" class=\"external\">MobileNetV2</a> pre-trained model <a href=\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\" class=\"external\">from TensorFlow Hub</a>. Any <a href=\"https://tfhub.dev/s?module-type=image-feature-vector&q=tf2\" class=\"external\">compatible image feature vector model</a> from TensorFlow Hub will work here, including the examples from the drop-down menu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bw8Jf94DSnP"
      },
      "outputs": [],
      "source": [
        "if 'transfer' == useArchitecture:\n",
        "  mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "  inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "  resnet_v2_50 = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "  featureExtractorModel = resnet_v2_50 #@param [\"mobilenet_v2\", \"inception_v3\", \"resnet_v2_50\"] {type:\"raw\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgwmHugQF-PD"
      },
      "source": [
        "Create the feature extractor by wrapping the pre-trained model as a Keras layer with [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer). Use the `trainable=False` argument to freeze the variables, so that the training only modifies the new classifier layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wB030nezBwI"
      },
      "outputs": [],
      "source": [
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    featureExtractorModel,\n",
        "    input_shape=(224, 224, 3),\n",
        "    trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QzVdu4ZhcDE"
      },
      "source": [
        "The feature extractor returns a 1280-long vector for each image (the image batch size remains at 32 in this example):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "Of7i-35F09ls",
        "outputId": "09693f79-506d-4d3c-ea01-03f67f7645f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c3c279ed0d5a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagesBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'imagesBatch' is not defined"
          ]
        }
      ],
      "source": [
        "feature_batch = feature_extractor_layer(imagesBatch)\n",
        "print(feature_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Attach a classification head\n",
        "\n",
        "To complete the model, wrap the feature extractor layer in a `tf.keras.Sequential` model and add a fully-connected layer for classification:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQq_kCWzlqSu",
        "outputId": "ca4c8572-6a1f-4bcf-8602-d359c8def3f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "numberOfClasses = len(classNames)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(numberOfClasses)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyhX4VCFmzVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "4443a06f-79c7-4696-aa5b-228a2c2abcd3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-15cbc1e18b08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagesBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'imagesBatch' is not defined"
          ]
        }
      ],
      "source": [
        "predictions = model(imagesBatch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQdUaTkzm3jQ",
        "outputId": "31b9d78a-b666-4650-b5df-2aa4e7c5bd25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([32, 10])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xRx8Rjzm67O"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "log_dir = rootLogsDirectory + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V03LhODI5rsP"
      },
      "outputs": [],
      "source": [
        "def getCallbacks(datasetName, modelName, earlyStoppingMetric, earlyStoppingMinimumImprovementCriterion, earlyStoppingPatience,\n",
        "                 baselineAccuracy,\n",
        "                 learningRateReductionMetric, learningRateReductionFactor, patienceForLearningRateReduction,\n",
        "                 learningRateReductionMinimumImprovementCriterion, learningRateReductionCooldown):\n",
        "  callbackList = []\n",
        "\n",
        "  callbackList.append(BackupAndRestore(backup_dir = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/tmpModelBackup/' + modelName + 'epoch_{epoch:04d}.h5', save_freq = 'epoch',\n",
        "                                    delete_checkpoint = True, save_before_preemption = False))\n",
        "\n",
        "  callbackList.append(EarlyStopping(monitor = earlyStoppingMetric, min_delta = earlyStoppingMinimumImprovementCriterion, patience = earlyStoppingPatience,\n",
        "                                    verbose = 1, mode = 'auto', baseline = None, restore_best_weights = True, start_from_epoch = 0))\n",
        "\n",
        "  #def learningrateSchedule(currentEpochNumber, learningRatefromPreviousEpoch):\n",
        "  #  learningRateForCurrentEpoch = learningRatefromPreviousEpoch\n",
        "  #  return learningRateForCurrentEpoch\n",
        "\n",
        "  #callbackList.append(LearningRateScheduler(learningRateSchedule(epoch, lr), verbose = 1))\n",
        "\n",
        "  #callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject/' + datasetName + '/models/allTrainingModels/' + modelName + 'epoch_{epoch:04d}.h5',\n",
        "  #                                    monitor = 'val_loss', verbose = 1, save_best_only = False, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "  #                                    options = None, initial_value_threshold = None))\n",
        "  callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject' + datasetName + '/models/finalModels/' + modelName + 'MostAccurateEpoch_{epoch:04d}.h5',\n",
        "                                      monitor = 'val_accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "                                      options = None, initial_value_threshold = baselineAccuracy))\n",
        "  callbackList.append(ModelCheckpoint(filepath = '/content/drive/My Drive/SEMProject' + datasetName + '/models/finalModels/' + modelName + 'LeastLossEpoch_{epoch:04d}.h5',\n",
        "                                      monitor = 'val_loss', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', save_freq = 'epoch',\n",
        "                                      options = None, initial_value_threshold = None))\n",
        "\n",
        "  callbackList.append(ReduceLROnPlateau(monitor = learningRateReductionMetric, factor = learningRateReductionFactor, patience = patienceForLearningRateReduction,\n",
        "                                        verbose = 1, mode='auto', min_delta = learningRateReductionMinimumImprovementCriterion, cooldown = learningRateReductionCooldown,\n",
        "                                        min_lr = minimumLearningRate))\n",
        "\n",
        "  callbackList.append(TerminateOnNaN())\n",
        "\n",
        "  callbackList.append(tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
        "\n",
        "  return callbackList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI0yAKd-nARd",
        "outputId": "72a6fb7a-a7b7-4015-ed21-595b95f6cbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 1.0633 - accuracy: 0.6603\n",
            "Epoch 10: val_accuracy improved from 0.50000 to 0.50288, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0010.h5\n",
            "\n",
            "Epoch 10: val_loss improved from inf to 1.50547, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0010.h5\n",
            "109/109 [==============================] - 844s 8s/step - loss: 1.0633 - accuracy: 0.6603 - val_loss: 1.5055 - val_accuracy: 0.5029 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.9852 - accuracy: 0.6825\n",
            "Epoch 11: val_accuracy improved from 0.50288 to 0.50978, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0011.h5\n",
            "\n",
            "Epoch 11: val_loss improved from 1.50547 to 1.46016, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0011.h5\n",
            "109/109 [==============================] - 797s 7s/step - loss: 0.9852 - accuracy: 0.6825 - val_loss: 1.4602 - val_accuracy: 0.5098 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.9535 - accuracy: 0.6974\n",
            "Epoch 12: val_accuracy improved from 0.50978 to 0.51093, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0012.h5\n",
            "\n",
            "Epoch 12: val_loss improved from 1.46016 to 1.44080, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0012.h5\n",
            "109/109 [==============================] - 798s 7s/step - loss: 0.9535 - accuracy: 0.6974 - val_loss: 1.4408 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.7080\n",
            "Epoch 13: val_accuracy improved from 0.51093 to 0.52359, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0013.h5\n",
            "\n",
            "Epoch 13: val_loss improved from 1.44080 to 1.42700, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0013.h5\n",
            "109/109 [==============================] - 795s 7s/step - loss: 0.9264 - accuracy: 0.7080 - val_loss: 1.4270 - val_accuracy: 0.5236 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.9019 - accuracy: 0.7135\n",
            "Epoch 14: val_accuracy improved from 0.52359 to 0.53740, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0014.h5\n",
            "\n",
            "Epoch 14: val_loss improved from 1.42700 to 1.41862, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0014.h5\n",
            "109/109 [==============================] - 732s 7s/step - loss: 0.9019 - accuracy: 0.7135 - val_loss: 1.4186 - val_accuracy: 0.5374 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.8795 - accuracy: 0.7190\n",
            "Epoch 15: val_accuracy improved from 0.53740 to 0.54315, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0015.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 1.41862 to 1.41443, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0015.h5\n",
            "109/109 [==============================] - 797s 7s/step - loss: 0.8795 - accuracy: 0.7190 - val_loss: 1.4144 - val_accuracy: 0.5432 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.8587 - accuracy: 0.7230\n",
            "Epoch 16: val_accuracy improved from 0.54315 to 0.54776, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0016.h5\n",
            "\n",
            "Epoch 16: val_loss improved from 1.41443 to 1.41345, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultLeastLossEpoch_0016.h5\n",
            "109/109 [==============================] - 790s 7s/step - loss: 0.8587 - accuracy: 0.7230 - val_loss: 1.4134 - val_accuracy: 0.5478 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "109/109 [==============================] - ETA: 0s - loss: 0.8394 - accuracy: 0.7293\n",
            "Epoch 17: val_accuracy improved from 0.54776 to 0.55351, saving model to /content/drive/My Drive/SEMProjectSEM500/models/finalModels/SEM500_LabelEncoded_simpleTransferLearning_Resnet_v2_50_rgb_notCropped_augemnted_learningRateReduction10x_seed108_restDefaultMostAccurateEpoch_0017.h5\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.41345\n",
            "109/109 [==============================] - 785s 7s/step - loss: 0.8394 - accuracy: 0.7293 - val_loss: 1.4150 - val_accuracy: 0.5535 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "100/109 [==========================>...] - ETA: 47s - loss: 0.8260 - accuracy: 0.7356"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 50\n",
        "\n",
        "history = model.fit(trainingDataset,\n",
        "                    validation_data=validationDataset,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=getCallbacks(datasetName, modelName, earlyStoppingMetric, earlyStoppingMinimumImprovementCriterion, earlyStoppingPatience,\n",
        "                                           baselineAccuracy, learningRateReductionMetric, learningRateReductionFactor, patienceForLearningRateReduction,\n",
        "                                           learningRateReductionMinimumImprovementCriterion, learningRateReductionCooldown))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiDbmiAK_h03"
      },
      "source": [
        "Start the TensorBoard to view how the metrics change with each epoch and to track other scalar values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "mCz7Hn2bevfW",
        "outputId": "825c35f4-4a7f-4a24-d917-20ada1eeade6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-68e0c25c23df>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'log_dir' is not defined"
          ]
        }
      ],
      "source": [
        "log_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mHBkANzILTH"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/SEMProject/SEM500/logs/fit/20230417-111244 --port=7005"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVvj6mi7WyuG"
      },
      "outputs": [],
      "source": [
        "def saveHistoryAndFinalModel(model, modelSaveLoaction, history, historySaveLoaction):\n",
        "  with open(historySaveLocation, 'wb') as file_pi:\n",
        "      pickle.dump(history.history, file_pi)\n",
        "\n",
        "  model.save(modelSaveLocation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTBQnMVRW1s1"
      },
      "outputs": [],
      "source": [
        "def plotHistory(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  #plt.plot(history.history['crossentropy'])\n",
        "  #plt.plot(history.history['val_crossentropy'])\n",
        "  #plt.title('model cross entropy')\n",
        "  #plt.ylabel('cross entropy')\n",
        "  #plt.xlabel('epoch')\n",
        "  #plt.legend(['train', 'validation'], loc='upper left')\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "291r4hLnW9jS"
      },
      "outputs": [],
      "source": [
        "def PerformanceReports(confusionMatrix,classificationReport,labels):\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(confusionMatrix, annot=True,ax=ax)\n",
        "    #labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels(labels)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(pd.DataFrame(classificationReport).iloc[:-1, :].T,\n",
        "                annot=True,ax=ax)\n",
        "    ax.set_title('Classification Report')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYVrwZa2W_37"
      },
      "outputs": [],
      "source": [
        "def evaluateModelOnDataset(model, dataset):\n",
        "  predictedClasses = np.array([])\n",
        "  trueLabels = np.array([])\n",
        "\n",
        "  for x, y in dataset:\n",
        "      predictedClasses = np.concatenate([predictedClasses, np.argmax(model(x), axis=-1)])\n",
        "      trueLabels = np.concatenate([trueLabels, np.argmax(y.numpy(), axis=-1)])\n",
        "\n",
        "  confusionMatrix = confusion_matrix(labels= trueLabels, predictions=predictedClasses).numpy()\n",
        "  classificationReport=classification_report(trueLabels, predictedClasses,\n",
        "                                      target_names=classNames,\n",
        "                                      output_dict=True)\n",
        "  PerformanceReports(confusionMatrix, classificationReport, classNames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q7gmDFWXD3s"
      },
      "outputs": [],
      "source": [
        "def evaluatedModel(model):\n",
        "  scoresTraining = model.evaluate(trainingDataset,verbose=1)\n",
        "  scoresValidation = model.evaluate(validationDataset,verbose=1)\n",
        "  scoresTesting = model.evaluate(testingDataset,verbose=1)\n",
        "  print(\"Train Accuracy: %.2f%%\" % (scoresTraining[1]*100))\n",
        "  print(\"Validation Accuracy: %.2f%%\" % (scoresValidation[1]*100))\n",
        "  print(\"testing Accuracy: %.2f%%\" % (scoresTesting[1]*100))\n",
        "\n",
        "  #print(history.history.keys())\n",
        "  plotHistory(history)\n",
        "  if doSeperateFineTuning:\n",
        "    plotHistory(historyFineTuning)\n",
        "\n",
        "  evaluateModelOnDataset(model, trainingDataset)\n",
        "  evaluateModelOnDataset(model, validationDataset)\n",
        "  evaluateModelOnDataset(model, testingDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oeJJ3MDXSSw"
      },
      "outputs": [],
      "source": [
        "evaluatedModel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYcvBSPBeJ8x"
      },
      "outputs": [],
      "source": [
        "saveHistoryAndFinalModel(model, modelSaveLocation, history, historySaveLocation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36a9d7cab8c8"
      },
      "source": [
        "<!-- <img class=\"tfo-display-only-on-site\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/images/tensorboard_transfer_learning_with_hub.png?raw=1\"/> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "### Check the predictions\n",
        "\n",
        "Obtain the ordered list of class names from the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGbEf5l1I4jz"
      },
      "outputs": [],
      "source": [
        "predicted_batch = model.predict(imagesBatch)\n",
        "predicted_id = tf.math.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = classNames[predicted_id]\n",
        "print(predicted_label_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "Plot the model predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hW3Ic_ZlwtrZ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(imagesBatch[n])\n",
        "  plt.title(predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRcJnAABr22x"
      },
      "source": [
        "## Export and reload your model\n",
        "\n",
        "Now that you've trained the model, export it as a SavedModel for reusing it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLcqg-RmsLno"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "model.save(export_path)\n",
        "\n",
        "export_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhQ9liIUsPsi"
      },
      "source": [
        "Confirm that you can reload the SavedModel and that the model is able to output the same results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nI5fvkAQvbS"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.keras.models.load_model(export_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZO14taYPH6"
      },
      "outputs": [],
      "source": [
        "resultsBatch = model.predict(imagesBatch)\n",
        "reloaded_resultsBatch = reloaded.predict(imagesBatch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtjsIPjQnPyM"
      },
      "outputs": [],
      "source": [
        "abs(reloaded_resultsBatch - resultsBatch).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jor83-LqI8xW"
      },
      "outputs": [],
      "source": [
        "reloaded_predicted_id = tf.math.argmax(reloaded_resultsBatch, axis=-1)\n",
        "reloaded_predicted_label_batch = classNames[reloaded_predicted_id]\n",
        "print(reloaded_predicted_label_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkQIBksVkxPO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(imagesBatch[n])\n",
        "  plt.title(reloaded_predicted_label_batch[n].title())\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSBRrW-MqBbk"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "You can use the SavedModel to load for inference or convert it to a [TensorFlow Lite](https://www.tensorflow.org/lite/models/convert/)  model (for on-device machine learning) or a [TensorFlow.js](https://www.tensorflow.org/js/tutorials#convert_pretrained_models_to_tensorflowjs) model (for machine learning in JavaScript).\n",
        "\n",
        "Discover [more tutorials](https://www.tensorflow.org/hub/tutorials) to learn how to use pre-trained models from TensorFlow Hub on image, text, audio, and video tasks."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kb__ZN8uFn-D"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}